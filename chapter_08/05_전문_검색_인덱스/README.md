# 전문 검색 인덱스 
- B-Tree 인덱스는 실제 컬럼의 값이 1MB여도, 전체 값을 인덱스 키로 사용하지 않음
  - 특정 값까지만 잘라서 인덱스 키로 사용함 
    - MyISAM = 1000byte
    - InnoDB = 3072byte
- 또한, 전체 일치 또는 좌측 일부 일치와 같은 검색만 가능 


문서의 내용 전체를 인덱스화해서 특정 키워드가 포함된 문서를 검색하는 전문(Full Text) 검색에는 일반적인 용도의 B-Tree 인덱스 사용 불가 
- 문서 전체에 대한 분석과 검색을 위한 전문 검색(Full Text search) 인덱스 알고리즘을 사용해야 한다.

<br/><br/>
## 인덱스 알고리즘 
- 문서 본문의 내용에서 사용자가 검색하게 될 키워드 분석 -> 빠른 검색용으로 사용할 수 있도록 키워드로 인덱스 구축 
- 키워드 인덱싱 방법에 따라 아래와 같이 구분  
  - 단어의 어근 분석 
  - n-gram 분석 

### 어근 분석 알고리즘 
mysql 서버의 전문 검색 인덱스는 다음 두 가지 중요한 과정을 거쳐 인덱싱이 수행됨 
- 불용어(Stop Word) 처리
- 어근 분석(Stemming)


#### 불용어 처리 
- 별 가치가 없는 단어를 모두 필터링해서 제거하는 작업 
- 불용어 개수는 많지 않아, 알고리즘을 구현한 코드에 모두 상수로 정의해서 사용하는 경우가 많음
- 유연성을 위해 불용어 자체를 DB화 -> 사용자가 추가/삭제할 수 있게 구현하는 경우도 있음 


#### 어근 분석
- 검색어로 선정된 단어의 뿌리인 원형을 찾는 작업 
- MeCab : 오픈소스 형태소 분석 라이브러리 
  - 한글이나 일본어의 경우, 영어와 같이 단어의 변형 자체는 거의 없음
  - 어근 분석 보다는 **문장의 형태소를 분석**해서 명사와 조사를 구분하는 기능이 더 중요함 
  - MeCab은 일본어를 위한 형태소 분석 프로그램 (한국어는 일본어와 많이 비슷하여 이를 이용해 분석 가능) 
  - 서구권 언어 -> MongoDB의 Snowball 
  - 단어 사전 필요 
  - 문장 해체 -> 각 단어의 품사를 식별할 수 있는 문장의 구조 인식 필요 
    - 이를 학습하는 과정이 필요 -> 한글에 맞게 완성도를 갖추는 작업은 많은 시간과 노력이 필요함

<br/><br/>
### n-gram 알고리즘
- MeCab은 전문 검색 알고리즘 -> 만족할만한 결과를 내기 위해서는 많은 노력과 시간 필요
  - 전문적인 검색 엔진을 고려할 때나 적용 검토함
- n-gram 알고리즘은 MeCab의 단점을 보완하기 위해 도입됨 
  - 형태소 분석 : 문장을 이해하는 알고리즘 
  - n-gram : 단순히 키워드를 검색해내기 위한 인덱싱 알고리즘


- 본문을 무조건 몇 글자씩 잘라서 인덱싱하는 방법 
  - 형태소 분석보다는 알고리즘이 단순한 편
  - 만들어진 인덱스의 크기는 상당히 큰 편 
- n : 인덱싱 할 키워드의 최소 글자 수 
  - 2글자 단위로 쪼갬 -> 2-gram(or Bi-gram) -> 해당 방식을 많이 사용함


```text
[ 2-gram 예시 ]
To be or not to be. That is the question
- 공백, 마침표 기준 10개의 단어 
- 2글자씩 중첩해서 토큰으로 분리됨 
  - 10글자 단어인 경우, 2-gram 알고리즘에서는 (10-1)개의 토큰으로 구분됨  

[ 토큰 구분 방식 ]
abcdefghij 라는 10글자 단어가 있다고 할 때
+---+---+---+---+---+---+---+---+---+---+
| a | b | c | d | e | f | g | h | i | j |
+---+---+---+---+---+---+---+---+---+---+
|-token-|   |   |   |
    |-token-|   |   |
        |-token-|   |
            |-token-| ...
            
- ab, bc, cd, de, ef, fg, gh, hi, ij 총 9개의 토큰이 생성 됨 
- 이렇게 구분된 토큰들을 인덱스에 저장함 
- 중복된 토큰은 하나의 인덱스 엔트리로 병합되어 저장됨
```

- MySQL은 이렇게 생성된 토큰들에 대해 불용어를 걸러내는 작업을 수행함 
  - 불용어와 동일하거나 불용어를 포함하는 경우 걸러서 버림 
- 구분된 토큰을 단순한 B-Tree에 저장한다.


### 불용어 변경 및 삭제 
- 불용어 기능은 도움이 되기보다 사용자를 더 혼란스럽게 만드는 기능일 수도 있음 
  - 차라리 불용어 처리 자체를 완전히 무시하거나, 서버에 내장된 불용어 대신 사용자가 직접 불용어를 등록하는 것을 권장함 

#### 불용어 처리 무시 
- 불용어를 완전히 제거 
  - `my.cnf`(MySQL 서버 설정 파일) 상의 `ft_stopword_file`시스템 변수에 빈 문자열 설정
    - 시스템 변수는 서버가 시작될 때만 인지하기 때문에 서버를 재시작 해야함
  - innodb 테이블의 불용어 처리 무시 방법
    - `innodb_ft_enable_stopword` 시스템 변수를 off로 설정 

#### 사용자 정의 불용어 
- 불용어 목록을 파일로 저장 -> 서버 설정 파일에서 `ft_stopword_file`에 경로를 등록
- innodb 엔진에서만 사용할 수 있는 방법
  - 불용어 목록을 테이블로 저장 -> `innodb_ft_server_stopword_table`시스템 변수에 불용어 테이블 설정
  - 설정이 된 이후 전문 검색 인덱스가 생성되어야 변경된 불용어가 적용 됨 

<br/><br/>

## 전문 검색 인덱스의 가용성 
### 사용 조건 
- 쿼리 문장이 전문 검색을 위한 문법일 것 (match ... against ...)
- 테이블이 전문 검색 대상 칼럼에 대해 전문 인덱스를 보유할 것 
```mysql
-- 풀 테이블 스캔 발생 
SELECT * FROM tb_test WHERE doc_body LIKE '%애플%';

-- 전문 검색 인덱스 사용 
SELECT * FROM th_test WHERE MATCH(doc_body) AGAINST('애플' IN BOOLEAN MODE);
```